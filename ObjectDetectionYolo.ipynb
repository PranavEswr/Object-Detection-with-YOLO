{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01158cca-6707-46b2-a49b-9d779dd371b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# define the minimum confidence (to filter weak detections), \n",
    "# Non-Maximum Suppression (NMS) threshold, and the green color\n",
    "confidence_thresh = 0.5\n",
    "NMS_thresh = 0.3\n",
    "green = (0, 255, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e854326-d7f2-49df-827e-64f5858d0d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# define the minimum confidence (to filter weak detections), \n",
    "# Non-Maximum Suppression (NMS) threshold, and the green color\n",
    "confidence_thresh = 0.5\n",
    "NMS_thresh = 0.3\n",
    "green = (0, 255, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ea5242e-cb09-4dbc-b6ef-841aa8ad52ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image and get its dimensions\n",
    "image = cv2.imread(\"examples/images/2.jpg\")\n",
    "# resize the image to 25% of its original size\n",
    "image = cv2.resize(image, \n",
    "                    (int(image.shape[0] * 0.25), \n",
    "                     int(image.shape[1] * 0.25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4226515-afa8-47d8-b08e-0d6e6dac2711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the image dimensions\n",
    "h = image.shape[0]\n",
    "w = image.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5b83772-9f12-48ac-8c83-c06c0a53a3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the class labels the model was trained on\n",
    "classes_path = \"yolov3-config/coco.names\"\n",
    "with open(classes_path, \"r\") as f:\n",
    "    classes = f.read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bf714c9-7134-4af5-b398-cd71c7d2ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the configuration and weights from disk\n",
    "yolo_config = \"yolov3-config/yolov3.cfg\"\n",
    "yolo_weights = \"yolov3-config/yolov3.weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ae36cf3-4fd2-4c7f-9644-1a603f79830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load YOLOv3 network pre-trained on the COCO dataset\n",
    "net = cv2.dnn.readNetFromDarknet(yolo_config, yolo_weights)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3f1dea0-065b-4ac1-9c48-c54eae50fde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the name of all the layers in the network\n",
    "layer_names = net.getLayerNames()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e422c50d-5597-4996-b2e3-e1a49a5e6bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the output layers\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57a9f51a-cbbf-4b25-ad4b-4d8f6aa11ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO Object Detection\n",
    "# layer_names = net.getLayerNames() output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "# Don't need to indexing i in layer_names[i[0] - 1] . Just remove it and do layer_names[i - 1]\n",
    "# layer_names = net.getLayerNames() output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7b7e42d-e935-46ba-894f-f81e2060b9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a blob from the image\n",
    "blob = cv2.dnn.blobFromImage(\n",
    "    image, 1 / 255, (416, 416), swapRB=True, crop=False)\n",
    "# pass the blob through the network and get the output predictions\n",
    "net.setInput(blob)\n",
    "outputs = net.forward(output_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "774690e2-0241-4733-8ba5-07d7cadb90c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty lists for storing the bounding boxes, confidences, and class IDs\n",
    "boxes = []\n",
    "confidences = []\n",
    "class_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "502aa728-38d0-4e96-b322-d0f3e0836cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the output predictions\n",
    "for output in outputs:\n",
    "    # loop over the detections\n",
    "    for detection in output:\n",
    "        # get the class ID and confidence of the dected object\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence  = scores[class_id]\n",
    "\n",
    "        # we keep the bounding boxes if the confidence (i.e. class probability) \n",
    "        # is greater than the minimum confidence \n",
    "        if confidence > confidence_thresh:\n",
    "            # perform element-wise multiplication to get\n",
    "            # the coordinates of the bounding box\n",
    "            box = [int(a * b) for a, b in zip(detection[0:4], [w, h, w, h])]\n",
    "            center_x, center_y, width, height = box\n",
    "            \n",
    "            # get the top-left corner of the bounding box\n",
    "            x = int(center_x - (width / 2))\n",
    "            y = int(center_y - (height / 2))\n",
    "\n",
    "            # append the bounding box, confidence, and class ID to their respective lists\n",
    "            class_ids.append(class_id)\n",
    "            confidences.append(float(confidence))\n",
    "            boxes.append([x, y, width, height])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d9fcca1-bb5e-4b1e-ac88-943e6077a715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the bounding boxes on a copy of the original image \n",
    "# before applying non-maxima suppression\n",
    "image_copy = image.copy()\n",
    "for box in boxes:\n",
    "    x, y, width, height = box\n",
    "    cv2.rectangle(image_copy, (x, y), (x + width, y + height), green, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "caf1243f-bdd7-4fb9-86c0-07113b376e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the output image\n",
    "cv2.imshow(\"Before NMS\", image_copy)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a9f402f-597d-49bf-8f15-e5aa4219ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply non-maximum suppression to remove weak bounding boxes that overlap with others.\n",
    "indices = cv2.dnn.NMSBoxes(boxes, confidences, confidence_thresh, NMS_thresh)\n",
    "indices = indices.flatten()\n",
    "for i in indices:\n",
    "    (x, y, w, h) = boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3]\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), green, 2)\n",
    "    text = f\"{classes[class_ids[i]]}: {confidences[i] * 100:.2f}%\"\n",
    "    cv2.putText(image, text, (x, y - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, green, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f640ad8-9819-46d8-b353-8874673a79b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the output image\n",
    "cv2.imshow(\"After NMS\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d1c3f-d66f-423a-8ca0-95927ea3bffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45975e9f-c21c-4d52-a282-5fe893475d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
